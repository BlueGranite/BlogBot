======== SAMPLE 1 ========
s of the data (and a nice table to get the data, too).  The next element is the key-value pairs. Think of these expressions as slices of code. When you call a key-value statement, the R code inside of R is executed, while code is written in the file location specified by the call context. When a key-value call is made to a file, R converts the newly converted file to a file-readable format. This is extremely valuable for report or dashboard developers that need to maintain a consistent R code store for everything from key-value handling to presentation of report content to text output to key-value interactions. The key-value store in R is pattern matching – we think we can get every pair of values in a pair of data points, but there are often only a handful of them. In this scenario, a developer writes only the data in a file and only runs the code. In production, key-value experts report for analysts that focus on only the most important data. Key-value analysis is more forgiving – often, there are multiple sets of data to perform key-value matches on. This leaves a single data source, but that doesn’t mean the developer doesn’t write the following code to retrieve the data:  The developer then needs to reproduce the process through the command line:  In the example above, the developer reports to “sanne@skyscraper.com”, which is 7:00 p.m. to 8:00 p.m. EST. The file that contains the body for the triplet “skyseriesx” is included in the list of locations for the data warehouse. However, the developer wanted to include the body with the retail sales dataset as well. To do this, the R code that was being created would have needed to use R’ly or simpler, without needing to explicitly choose which files to retrieve. Writing these basic R code was just a matter of doing the leg work. The developer chose to retrieve the retail dataset as the source and call this specific function through the web client and SQL Server Integration Services (SSIS) interface. Quite simply, the sales dataset was AlabamaAlaRedGranite’s only source with which to perform complex key-value pairs across multiple data sources. With this API, we could leverage multiple stakeholders and multiple data sources simultaneously and have a store that is, on average, about the same price as a single MPP store. At BlueGranite, we use this model often in prototypical retail and restaurant architecture. Since the store is not only an MPP store, but also intends to categorize and analyzeably target to multiple business sources of data, we wanted to create a model that represented a consistent, on-demand, accurate, in real-time, slice-of-life, cost-effectiveness. We wanted a “Real Time Analysis-like” model that represented just a few of the many options available to integrate its key-value mix seamlessly. With this new API end user will be able to generate and return results based on easily accessible real-time, up to 10,000 sales summary columns (kB) ready for analysis. While the original R Sales app used kB as the API endpoint, the new R Sales app uses 1.0’-“-“ million sales items per day to provide consistent, accurate, real-time, on-demand business intelligence. With the addition of kRPCB, the business will now need to run these summary columns on a daily cycle and thus need a way to query the sales every day. With this new capability, the developer will have the ability to run multiple sales scenarios and record millions of rows of information for analysts to analyze. With retail accounting for almost half of the Sales Inc whitepaper (available here too), this fact alone strongly supports the business’s case for using retail as the source for their key-value model. To demonstrate this capability, one simple example comes from one of our stores. After all their daily sales are consolidated and aggregated so that only the major sales authors have access to the top 100 million sales records. But how can this be done? Retailers are not normal restaurants; they are a vegan restaurant. Sales authors at BlueGranite know that good sales data exists but they don’t know that bad sales data exists but they don’t know that positive sales data exists but they reside in the latter. This means that if a store closes the number of positive sales goes up again. So how can they do this without giving up on key-value modeling? By creating a key-value analysis framework they create a key-value store! How does one do that? Easy! Robust self-service BI tools are focused on building digital tools that help consumers do more with their data. Those include the Microsoft Power BI service, Dynamics<U+202D> Office 365, and social media tools. Play
