======== SAMPLE 1 ========
 easily provide a visual representation of the number of tiles in the map, as well as how many tiles are represented in the tile. The data is then converted to a table and column table, which is then exported and loaded into Power BI Desktop. The export function can be found in the Export function utility under the Map functions pane, and can be used to import data from data sources such as Power BI Desktop, CSV, Excel, or JSON. In addition, exporting can be configured to send alerts to the Power BI service from within PowerShell, as can enabling Power Query. We will add additional sample Export function functions sections in the next section, where the functionality is useful for an enterprise specific use case, or for use in the cloud. With a visual representation of the number of tiles in the map in mind, let’s use the export function to create a table in Excel containing the columns in a table we have created, and which has two distinct columns and a different row in its tile. From Excel, we can see all the values in our table as a table and create and use the export function within Power BI Desktop, as shown below:  The Export function works on two levels – Column One – to give Power BI users the ability to import data from various sources. For this example, we will create a table which has four table columns, column-by-columns data, as well as two distinct row values, column-by-row. If we do the math, the two tables combined represent 5,927,542,931 tile-level rows in Power BI Desktop. Note: You can click on the image to view a live copy of the code for the Import function with Excel. The Data Source table also has distinct rows in its tile, so we will also have two distinct values in our table as well. The same export function can be used to create custom visuals in the cloud to give the visuals and visuals for Power BI another try. By using PowerBI – the Microsoft Azure Web Services to deliver information, and the Azure Data Lake Analytics to deliver performance indicators, to deliver the visuals and visuals for Power BI, we can create visuals or visuals that are nearly perfect in the Azure world (that we might add to a BlueGranite or other external data warehouse). Once we have taken the Azure data services and our visualizations and visuals, we can create our own charts, graphics, or other Power BI content from those assets. Let’s see what we can do using the import function we just talked about! For the sake of brevity, I will not go into details about how to import data, but here are a few basic steps:      Use The Import Key As an example, let’s import data from Azure (as mentioned earlier) into Power BI.  Importing data from Power BI can’t be undone because all you need is the import key and the data into Power BI.                   Click the link to learn more:  Importing Data Into Power BI in Excel      What Does It All Mean? First let’s start by creating the import key from the Azure portal and adding the data into the destination data structure. Then we pull the data into table format. Next, we click the add button and we bring up the Import and Create table options dialog box. The data that you imported into the Data Lake Analytics gateway will then appear as well.        Click the drop-down arrow next to the Type of Data and Type of Data dialog box and choose the Type from the drop-down menu to Maximize the output by 10 and make the source data size to be 10TB (3,380,000 rows):  Click OK and your imported data will appear, with the new table returned to your Excel model. You can read more about the Import and Create function here. Finally, let’s go back to the source data structure and create another table. Let’s make the next set of transformations over that first table and add in our additional table. Notice how our tables are composed of a common row and a common column. Let’s rename the column names using the column name in the column-by-column table. The data is now imported into a separate table and its columns scaled up to be 540TB (690,000 rows). We could do the same size transformation for every column and also give us the new output column for the new table as well.  Click the orange button next to the Source table and select Transform column and click OK. Add the new source data structure to the top-level table and make a copy of that data and table as a new data type, along with the new result data. Click the white rectangle and choose Data Type in the top-level table and add the source data type.    The output looks similar to the screenshot below, except that since we have made the first transformation,
